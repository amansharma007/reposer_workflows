{
  "3": {
    "inputs": {
      "seed": 814619717275043,
      "steps": 40,
      "cfg": 7,
      "sampler_name": "ddpm",
      "scheduler": "karras",
      "denoise": 1,
      "model": [
        "4",
        0
      ],
      "positive": [
        "21",
        0
      ],
      "negative": [
        "7",
        0
      ],
      "latent_image": [
        "20",
        0
      ]
    },
    "class_type": "KSampler",
    "_meta": {
      "title": "KSampler"
    }
  },
  "4": {
    "inputs": {
      "ckpt_name": "v1-5-pruned-emaonly.ckpt"
    },
    "class_type": "CheckpointLoaderSimple",
    "_meta": {
      "title": "Load Checkpoint"
    }
  },
  "6": {
    "inputs": {
      "text": "korean man, yellow shirt, realistic, on london street, golden hour, detailed eyes, detailed face and detailed skin",
      "clip": [
        "4",
        1
      ]
    },
    "class_type": "CLIPTextEncode",
    "_meta": {
      "title": "CLIP Text Encode (Prompt)"
    }
  },
  "7": {
    "inputs": {
      "text": "(deformed iris, deformed pupils, semi-realistic, cgi, 3d, render, sketch, cartoon, drawing, anime), text, cropped, out of frame, worst quality, low quality, jpeg artifacts, ugly, duplicate, morbid, mutilated, extra fingers, mutated hands, poorly drawn hands, poorly drawn face, mutation, deformed, blurry, dehydrated, bad anatomy, bad proportions, extra limbs, cloned face, disfigured, gross proportions, malformed limbs, missing arms, missing legs, extra arms, extra legs, fused fingers, too many fingers, long neck, (embedding:baddream:1), (embedding:unrealisticdream:1), (embedding:badhands:1), (embedding:betterhands:1), (embedding:fastnegative:1), (embedding:negativehand:1)",
      "clip": [
        "4",
        1
      ]
    },
    "class_type": "CLIPTextEncode",
    "_meta": {
      "title": "CLIP Text Encode (Prompt)"
    }
  },
  "10": {
    "inputs": {
      "image": "vishnu.jpeg",
      "upload": "image"
    },
    "class_type": "LoadImage",
    "_meta": {
      "title": "Load Image"
    }
  },
  "12": {
    "inputs": {
      "model_name": "sam_hq_vit_h (2.57GB)"
    },
    "class_type": "SAMModelLoader (segment anything)",
    "_meta": {
      "title": "SAMModelLoader (segment anything)"
    }
  },
  "13": {
    "inputs": {
      "model_name": "GroundingDINO_SwinT_OGC (694MB)"
    },
    "class_type": "GroundingDinoModelLoader (segment anything)",
    "_meta": {
      "title": "GroundingDinoModelLoader (segment anything)"
    }
  },
  "14": {
    "inputs": {
      "prompt": "clothes",
      "threshold": 0.3,
      "sam_model": [
        "12",
        0
      ],
      "grounding_dino_model": [
        "13",
        0
      ],
      "image": [
        "10",
        0
      ]
    },
    "class_type": "GroundingDinoSAMSegment (segment anything)",
    "_meta": {
      "title": "GroundingDinoSAMSegment (segment anything)"
    }
  },
  "15": {
    "inputs": {
      "images": [
        "14",
        0
      ]
    },
    "class_type": "PreviewImage",
    "_meta": {
      "title": "Preview Image"
    }
  },
  "16": {
    "inputs": {
      "mask": [
        "14",
        1
      ]
    },
    "class_type": "InvertMask (segment anything)",
    "_meta": {
      "title": "InvertMask (segment anything)"
    }
  },
  "17": {
    "inputs": {
      "mask": [
        "16",
        0
      ]
    },
    "class_type": "MaskToImage",
    "_meta": {
      "title": "Convert Mask to Image"
    }
  },
  "18": {
    "inputs": {
      "images": [
        "17",
        0
      ]
    },
    "class_type": "PreviewImage",
    "_meta": {
      "title": "Preview Image"
    }
  },
  "19": {
    "inputs": {
      "control_net_name": "control_v11f1p_sd15_depth_fp16.safetensors"
    },
    "class_type": "ControlNetLoader",
    "_meta": {
      "title": "Load ControlNet Model"
    }
  },
  "20": {
    "inputs": {
      "grow_mask_by": 10,
      "pixels": [
        "14",
        0
      ],
      "vae": [
        "4",
        2
      ],
      "mask": [
        "16",
        0
      ]
    },
    "class_type": "VAEEncodeForInpaint",
    "_meta": {
      "title": "VAE Encode (for Inpainting)"
    }
  },
  "21": {
    "inputs": {
      "strength": 1,
      "conditioning": [
        "6",
        0
      ],
      "control_net": [
        "19",
        0
      ],
      "image": [
        "49",
        0
      ]
    },
    "class_type": "ControlNetApply",
    "_meta": {
      "title": "Apply ControlNet"
    }
  },
  "22": {
    "inputs": {
      "detect_hand": "enable",
      "detect_body": "enable",
      "detect_face": "enable",
      "resolution": 512
    },
    "class_type": "OpenposePreprocessor",
    "_meta": {
      "title": "OpenPose Pose"
    }
  },
  "23": {
    "inputs": {
      "images": [
        "49",
        0
      ]
    },
    "class_type": "PreviewImage",
    "_meta": {
      "title": "Preview Image"
    }
  },
  "42": {
    "inputs": {
      "seed": 726763308064543,
      "steps": 14,
      "cfg": 4.2,
      "sampler_name": "ddpm",
      "scheduler": "karras",
      "denoise": 0.45,
      "model": [
        "4",
        0
      ],
      "positive": [
        "21",
        0
      ],
      "negative": [
        "7",
        0
      ],
      "latent_image": [
        "47",
        0
      ]
    },
    "class_type": "KSampler",
    "_meta": {
      "title": "KSampler (Latent Upscale)"
    }
  },
  "44": {
    "inputs": {
      "upscale_by": 1.5,
      "seed": 88183735867109,
      "steps": 2,
      "cfg": 4.5,
      "sampler_name": "ddpm",
      "scheduler": "karras",
      "denoise": 0.21,
      "mode_type": "Linear",
      "tile_width": 576,
      "tile_height": 576,
      "mask_blur": 8,
      "tile_padding": 32,
      "seam_fix_mode": "None",
      "seam_fix_denoise": 1,
      "seam_fix_width": 64,
      "seam_fix_mask_blur": 8,
      "seam_fix_padding": 16,
      "force_uniform_tiles": false,
      "tiled_decode": false,
      "image": [
        "46",
        0
      ],
      "model": [
        "4",
        0
      ],
      "positive": [
        "21",
        0
      ],
      "negative": [
        "7",
        0
      ],
      "vae": [
        "4",
        2
      ],
      "upscale_model": [
        "48",
        0
      ]
    },
    "class_type": "UltimateSDUpscale",
    "_meta": {
      "title": "Ultimate SD Upscale"
    }
  },
  "45": {
    "inputs": {
      "filename_prefix": "Reposer_Final",
      "images": [
        "44",
        0
      ]
    },
    "class_type": "SaveImage",
    "_meta": {
      "title": "Save Image"
    }
  },
  "46": {
    "inputs": {
      "samples": [
        "42",
        0
      ],
      "vae": [
        "4",
        2
      ]
    },
    "class_type": "VAEDecode",
    "_meta": {
      "title": "VAE Decode"
    }
  },
  "47": {
    "inputs": {
      "upscale_method": "nearest-exact",
      "scale_by": 1,
      "samples": [
        "3",
        0
      ]
    },
    "class_type": "LatentUpscaleBy",
    "_meta": {
      "title": "Upscale Latent By"
    }
  },
  "48": {
    "inputs": {
      "model_name": "4x_foolhardy_Remacri.pth"
    },
    "class_type": "UpscaleModelLoader",
    "_meta": {
      "title": "Load Upscale Model"
    }
  },
  "49": {
    "inputs": {
      "resolution": 1024,
      "image": [
        "10",
        0
      ]
    },
    "class_type": "Zoe-DepthMapPreprocessor",
    "_meta": {
      "title": "Zoe Depth Map"
    }
  },
  "50": {
    "inputs": {
      "samples": [
        "3",
        0
      ],
      "vae": [
        "4",
        2
      ]
    },
    "class_type": "VAEDecode",
    "_meta": {
      "title": "VAE Decode"
    }
  },
  "51": {
    "inputs": {
      "images": [
        "50",
        0
      ]
    },
    "class_type": "PreviewImage",
    "_meta": {
      "title": "Preview Image"
    }
  }
}