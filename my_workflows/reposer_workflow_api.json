{
    "8": {
        "inputs": {
            "vae_name": "vae-ft-mse-840000-ema-pruned.ckpt"
        },
        "class_type": "VAELoader"
    },
    "16": {
        "inputs": {
            "ckpt_name": "SD1.5/realcartoon3d_v15.safetensors"
        },
        "class_type": "CheckpointLoaderSimple"
    },
    "18": {
        "inputs": {
            "text": "naked, nsfw, blurry, smooth, minimalist vector art, hand, fingers, camera, lens. bow-tie, lantern, lamp. drab, minimalism, pixel art. Gaussian noise, perlin. lowpoly."
        },
        "class_type": "CLIPTextEncode"
    },
    "21": {
        "inputs": {
            "width": [
                "208",
                0
            ],
            "height": [
                "208",
                1
            ],
            "batch_size": 1
        },
        "class_type": "EmptyLatentImage"
    },
    "30": {
        "inputs": {
            "text": "HDR photo of a woman, 1970s style African detective, cheering. In the background is her office desk and a window looking out over the New York City skyline."
        },
        "class_type": "CLIPTextEncode"
    },
    "155": {
        "inputs": {
            "image": "pose_68be8a20-7006-44fd-82c3-2b9fb9c27a47.jpeg",
            "upload": "image"
        },
        "class_type": "LoadImage"
    },
    "156": {
        "inputs": {
            "control_net_name": "sd15/control-lora/control_lora_rank128_v11p_sd15_openpose_fp16.safetensors"
        },
        "class_type": "ControlNetLoader"
    },
    "161": {
        "inputs": {
            "image": "woman_81d8d14a-c5a6-4450-9e07-2c0b63dbaabb.jpeg",
            "upload": "image"
        },
        "class_type": "LoadImage"
    },
    "168": {
        "inputs": {
            "upscale_method": "nearest-exact",
            "megapixels": 0.5,
            "image": [
                "155",
                0
            ]
        },
        "class_type": "ImageScaleToTotalPixels"
    },
    "176": {
        "inputs": {
            "seed": 504913919791597,
            "steps": 16,
            "cfg": 5.6000000000000005,
            "sampler_name": "uni_pc",
            "scheduler": "karras",
            "denoise": 0.25,
            "model": [
                "252",
                0
            ],
            "positive": [
                "240",
                0
            ],
            "negative": [
                "240",
                1
            ],
            "latent_image": [
                "263",
                0
            ]
        },
        "class_type": "KSampler"
    },
    "208": {
        "inputs": {
            "image": [
                "168",
                0
            ]
        },
        "class_type": "GetImageSize"
    },
    "227": {
        "inputs": {
            "filename_prefix": "Reposer_S1",
            "images": [
                "302",
                0
            ]
        },
        "class_type": "SaveImage"
    },
    "238": {
        "inputs": {
            "detect_hand": "enable",
            "detect_body": "enable",
            "detect_face": "enable",
            "resolution": 512,
            "bbox_detector": "yolox_l.onnx",
            "pose_estimator": "dw-ll_ucoco_384.onnx",
            "scale_stick_for_xinsr_cn": "disable",
            "image": [
                "168",
                0
            ]
        },
        "class_type": "DWPreprocessor"
    },
    "240": {
        "inputs": {
            "strength": 1,
            "start_percent": 0,
            "end_percent": 1,
            "positive": [
                "30",
                0
            ],
            "negative": [
                "18",
                0
            ],
            "control_net": [
                "156",
                0
            ],
            "image": [
                "238",
                0
            ]
        },
        "class_type": "ControlNetApplyAdvanced"
    },
    "252": {
        "inputs": {
            "b1": 1.3,
            "b2": 1.4,
            "s1": 0.9,
            "s2": 0.2,
            "model": [
                "303",
                0
            ]
        },
        "class_type": "FreeU_V2"
    },
    "253": {
        "inputs": {
            "add_noise": "enable",
            "noise_seed": 1069931404185387,
            "steps": 20,
            "cfg": 5.5,
            "sampler_name": "heunpp2",
            "scheduler": "karras",
            "start_at_step": 0,
            "end_at_step": 10000,
            "return_with_leftover_noise": "disable",
            "model": [
                "291",
                0
            ],
            "positive": [
                "240",
                0
            ],
            "negative": [
                "240",
                1
            ],
            "latent_image": [
                "21",
                0
            ]
        },
        "class_type": "KSamplerAdvanced"
    },
    "256": {
        "inputs": {
            "ipadapter_file": "ip-adapter-full-face_sd15.safetensors"
        },
        "class_type": "IPAdapterModelLoader"
    },
    "257": {
        "inputs": {
            "clip_name": "ip_adapter_sd15/model.safetensors"
        },
        "class_type": "CLIPVisionLoader"
    },
    "259": {
        "inputs": {
            "interpolation": "LANCZOS",
            "crop_position": "center",
            "sharpening": 0,
            "image": [
                "161",
                0
            ]
        },
        "class_type": "PrepImageForClipVision"
    },
    "263": {
        "inputs": {
            "version": "SD 1.x",
            "upscale": 1.5,
            "latent": [
                "253",
                0
            ]
        },
        "class_type": "NNLatentUpscale"
    },
    "264": {
        "inputs": {
            "samples": [
                "253",
                0
            ],
            "vae": [
                "8",
                0
            ]
        },
        "class_type": "VAEDecode"
    },
    "266": {
        "inputs": {
            "model_name": "bbox/face_yolov8m.pt"
        },
        "class_type": "UltralyticsDetectorProvider"
    },
    "267": {
        "inputs": {
            "threshold": 0.52,
            "dilation": 10,
            "crop_factor": 1.2000000000000002,
            "drop_size": 10,
            "labels": "all",
            "bbox_detector": [
                "266",
                0
            ],
            "image": [
                "301",
                0
            ]
        },
        "class_type": "BboxDetectorSEGS"
    },
    "268": {
        "inputs": {
            "model_name": "sam_vit_b_01ec64.pth",
            "device_mode": "Prefer GPU"
        },
        "class_type": "SAMLoader"
    },
    "269": {
        "inputs": {
            "detection_hint": "mask-points",
            "dilation": 0,
            "threshold": 0.9400000000000001,
            "bbox_expansion": 0,
            "mask_hint_threshold": 0.7,
            "mask_hint_use_negative": "False",
            "sam_model": [
                "268",
                0
            ],
            "segs": [
                "267",
                0
            ],
            "image": [
                "301",
                0
            ]
        },
        "class_type": "SAMDetectorCombined"
    },
    "270": {
        "inputs": {
            "guide_size": 1024,
            "guide_size_for": false,
            "max_size": 1024,
            "seed": 329293744560011,
            "steps": 16,
            "cfg": 8.5,
            "sampler_name": "ddpm",
            "scheduler": "karras",
            "denoise": 0.3,
            "feather": 6,
            "noise_mask": true,
            "force_inpaint": true,
            "wildcard": "",
            "cycle": 1,
            "inpaint_model": false,
            "noise_mask_feather": 20,
            "image": [
                "301",
                0
            ],
            "segs": [
                "278",
                0
            ],
            "model": [
                "252",
                0
            ],
            "positive": [
                "275",
                0
            ],
            "negative": [
                "240",
                1
            ]
        },
        "class_type": "DetailerForEachDebug"
    },
    "271": {
        "inputs": {
            "images": [
                "270",
                1
            ]
        },
        "class_type": "PreviewImage"
    },
    "272": {
        "inputs": {
            "images": [
                "270",
                2
            ]
        },
        "class_type": "PreviewImage"
    },
    "273": {
        "inputs": {
            "images": [
                "270",
                3
            ]
        },
        "class_type": "PreviewImage"
    },
    "274": {
        "inputs": {
            "text": "a face",
            "clip": [
                "16",
                1
            ]
        },
        "class_type": "CLIPTextEncode"
    },
    "275": {
        "inputs": {
            "conditioning_1": [
                "274",
                0
            ],
            "conditioning_2": [
                "240",
                0
            ]
        },
        "class_type": "ConditioningCombine"
    },
    "277": {
        "inputs": {
            "filename_prefix": "Reposer_S2_Facefix",
            "images": [
                "270",
                0
            ]
        },
        "class_type": "SaveImage"
    },
    "278": {
        "inputs": {
            "segs": [
                "267",
                0
            ],
            "mask": [
                "269",
                0
            ]
        },
        "class_type": "ImpactSegsAndMask"
    },
    "283": {
        "inputs": {
            "images": [
                "264",
                0
            ]
        },
        "class_type": "PreviewImage"
    },
    "291": {
        "inputs": {
            "Input": 2
        },
        "class_type": "CR Model Input Switch"
    },
    "297": {
        "inputs": {
            "seed": 836315368333119,
            "steps": 14,
            "cfg": 5.5,
            "sampler_name": "dpmpp_2m",
            "scheduler": "karras",
            "denoise": 0.35000000000000003,
            "model": [
                "252",
                0
            ],
            "positive": [
                "240",
                0
            ],
            "negative": [
                "240",
                1
            ],
            "latent_image": [
                "298",
                0
            ]
        },
        "class_type": "KSampler"
    },
    "298": {
        "inputs": {
            "version": "SD 1.x",
            "upscale": 1.5,
            "latent": [
                "176",
                0
            ]
        },
        "class_type": "NNLatentUpscale"
    },
    "300": {
        "inputs": {
            "filename_prefix": "Reposer_S2",
            "images": [
                "301",
                0
            ]
        },
        "class_type": "SaveImage"
    },
    "301": {
        "inputs": {
            "samples": [
                "297",
                0
            ]
        },
        "class_type": "VAEDecode"
    },
    "302": {
        "inputs": {
            "samples": [
                "176",
                0
            ]
        },
        "class_type": "VAEDecode"
    },
    "303": {
        "inputs": {
            "weight": 1,
            "weight_type": "linear",
            "combine_embeds": "concat",
            "start_at": 0,
            "end_at": 1,
            "embeds_scaling": "V only",
            "model": [
                "16",
                0
            ],
            "ipadapter": [
                "256",
                0
            ],
            "image": [
                "259",
                0
            ],
            "clip_vision": [
                "257",
                0
            ]
        },
        "class_type": "IPAdapterAdvanced"
    }
}